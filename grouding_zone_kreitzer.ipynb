{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1d0a8-3b4b-4f89-8211-da527d67ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"GDAL_DATA\"] = \"/srv/conda/envs/notebook/share/gdal\" # need to specify to make gdal work\n",
    "os.environ[\"PROJ_LIB\"] = \"/srv/conda/envs/notebook/share/proj\" # need to specify to make pyproj work\n",
    "os.environ[\"PROJ_DATA\"] = \"/srv/conda/envs/notebook/share/proj\" # need to specify to make pyproj work\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm \n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import geopandas as gpd\n",
    "from ipyleaflet import Map, basemaps, Polygon, Polyline, GeoData, LayersControl\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from rasterio import warp\n",
    "import icepyx as ipx\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    from ed.edcreds import getedcreds\n",
    "except:\n",
    "    print('No earthdata credentials found.')\n",
    "    print('To set up, rename the folder \"ed_example\" to \"ed\".')\n",
    "    print('Then, add your earthdata credentials to \"ed/edcreds.py\".')\n",
    "\n",
    "from utils.nsidc import download_is2\n",
    "from utils.readers import read_atl06\n",
    "from utils.S2 import plotS2cloudfree, add_inset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d861dc4-b4a3-47ae-b05b-c8cb276f059f",
   "metadata": {},
   "source": [
    "## Show area of interest on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69daa2d-89b2-4bbb-a25b-5343cd142653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just drew these randomly on a map...\n",
    "shape = 'data/shapefiles/gilac-grounding.geojson'\n",
    "shape_buffer = 'data/shapefiles/kreitzer-region-large.geojson'\n",
    "\n",
    "gdf = gpd.read_file(shape)\n",
    "geom = [i for i in gdf.geometry]\n",
    "lons,lats = geom[0].exterior.coords.xy\n",
    "shape_coords = list(zip(lats,lons))\n",
    "shape_bounds = [[np.min(lats),np.min(lons)], [np.max(lats),np.max(lons)]]\n",
    "\n",
    "gdf = gpd.read_file(shape_buffer)\n",
    "geom = [i for i in gdf.geometry]\n",
    "lons,lats = geom[0].exterior.coords.xy\n",
    "shape_buffer_coords = list(zip(lats,lons))\n",
    "\n",
    "m=Map(basemap=basemaps.Esri.WorldImagery,center=[np.mean(lats),np.mean(lons)],zoom=7)\n",
    "m.fit_bounds(shape_bounds)\n",
    "polygon = Polygon(locations=shape_buffer_coords, color=\"red\", fill_color=\"red\", name='polygon_buffered')\n",
    "m.add_layer(polygon)\n",
    "polygon2 = Polygon(locations=shape_coords, color=\"blue\", fill_color=\"blue\", name='polygon')\n",
    "m.add_layer(polygon2)\n",
    "m.add_control(LayersControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8256d-f115-4c21-8c90-1928ca654625",
   "metadata": {},
   "source": [
    "## Download the ATL06 ICESat-2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c86803-b5f4-4861-9a77-adaf72b97e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"EARTHDATA_USERNAME\"] = getedcreds()[0]\n",
    "os.environ[\"EARTHDATA_PASSWORD\"] = getedcreds()[1]\n",
    "\n",
    "short_name = 'ATL06'\n",
    "spatial_extent = 'data/shapefiles/gilac-grounding.shp'\n",
    "temporal = ['2018-01-01','2030-01-01']\n",
    "region_a = ipx.Query(short_name, spatial_extent, temporal)\n",
    "results = region_a.avail_granules(ids=True)\n",
    "print('Found granules:')\n",
    "results_print = np.array(results).flatten()\n",
    "for i in range(np.min((len(results_print),10))):\n",
    "    print(results_print[i])\n",
    "if len(results_print)>10:\n",
    "    print('...and %d more results.' % (len(results_print)-10))\n",
    "region_a.avail_granules(ids=True)\n",
    "output_dir = 'data/IS2/v006'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee411586-7cba-464e-9d0d-d257e076d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to download again\n",
    "region_a.download_granules(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797410ab-18d8-4990-b717-4f5a21ab005b",
   "metadata": {},
   "source": [
    "### Get a list of all the ATL06 data files over this region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fd5b5-d6f3-4a58-b09a-17bf709e5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_for = 'ATL06_'\n",
    "search_in = output_dir + '/'\n",
    "filelist = [search_in+f for f in os.listdir(search_in) \\\n",
    "            if os.path.isfile(os.path.join(search_in, f)) & (search_for in f) & ('.h5' in f)]\n",
    "filelist.sort()\n",
    "print('There are %i files.' % len(filelist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b078fd-cb5f-4805-a1e2-f543f9a0e1f9",
   "metadata": {},
   "source": [
    "### Just pick the first file, and plot the ground tracks on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc2a65-8064-4f66-825b-8c48a08ef7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filelist[0]\n",
    "ancillary, dfs = read_atl06(file, verbose=False)\n",
    "for gtx in dfs.keys():\n",
    "    dfs[gtx] = dfs[gtx][dfs[gtx].qual_summary == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee7643-c428-4fdc-ad9c-9e72f1317ef9",
   "metadata": {},
   "source": [
    "### Some helpful ancillary data for an example ICESat-2 track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70871bd-2064-41ac-9d58-32b98eca4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancillary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a49a6d-e719-4919-aa31-c32c11f35744",
   "metadata": {},
   "source": [
    "### an example dataframe with ATL06 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e6c12-7421-4e8b-b352-a42c17cd9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603da86-a406-45c6-9b05-17f0013c545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['gt3l']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5da9c2-15c7-4aca-9f31-bd9df64c2899",
   "metadata": {},
   "source": [
    "### show a few tracks on a map to get an idea of coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e244310f-d3ea-4f07-a74a-6989f13bd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Map(basemap=basemaps.Esri.WorldImagery,\n",
    "      center=list(np.mean(np.array(shape_coords), axis=0)),\n",
    "      zoom=9)\n",
    "m.fit_bounds(shape_bounds)\n",
    "\n",
    "polygon = Polygon(locations=shape_coords, color=\"blue\", fill_color=\"blue\", name='polygon')\n",
    "m.add_layer(polygon)\n",
    "\n",
    "# plot the first 15 tracks\n",
    "nfiles = 15\n",
    "filelist.sort()\n",
    "for file in filelist[:nfiles]:\n",
    "    ancillary, dfs = read_atl06(file, verbose=False)\n",
    "    for gtx in dfs.keys():\n",
    "        dfs[gtx] = dfs[gtx][dfs[gtx].qual_summary == 0]\n",
    "        coords = list(zip(dfs[gtx].lat, dfs[gtx].lon))\n",
    "        weight = 2 if ancillary['gtx_strength_dict'][gtx] == 'strong' else 1\n",
    "        name = 'track %d-%s' % (ancillary['rgt'], gtx)\n",
    "        line = Polyline(locations=coords,color=\"red\",weight=weight,fill=False, name=name, opacity=0.25)\n",
    "        m.add_layer(line)\n",
    "\n",
    "m.add_control(LayersControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202bd4e9-859a-469a-8c86-e3b4ac3dd4f0",
   "metadata": {},
   "source": [
    "## get a dataframe with basic file info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575babdd-64f0-40f3-b52e-09822e7157f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.DataFrame({'filename': filelist})\n",
    "df_files['granule_id'] = df_files.apply(lambda x: x.filename[x.filename.find('ATL06_'):], axis=1)\n",
    "df_files['date'] = df_files.apply(lambda x: x.granule_id[6:10]+'-'+x.granule_id[10:12]+'-'+x.granule_id[12:14], axis=1)\n",
    "df_files['track'] = df_files.apply(lambda x: int(x.granule_id[21:25]), axis=1)\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912f9b5-4189-4c6b-82a8-a3ab41fb9031",
   "metadata": {},
   "source": [
    "## pick a track and GTX and show some repeat tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5e844-32dc-4595-a8a2-be66aebb507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = 721\n",
    "gtx = 'gt3l'\n",
    "# track = 226\n",
    "# gtx = 'gt3l'\n",
    "df_track = df_files[df_files.track == track].sort_values(by='date').reset_index(drop=True)\n",
    "nfiles = len(df_track)\n",
    "df_track.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec353a4-9551-40d9-9480-4a45814e2862",
   "metadata": {},
   "source": [
    "### show the tracks to make sure there are no outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb60986-9dca-4c54-ad11-11eb6c2c7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=Map(basemap=basemaps.Esri.WorldImagery,\n",
    "      center=list(np.mean(np.array(shape_coords), axis=0)),\n",
    "      zoom=9)\n",
    "m.fit_bounds(shape_bounds)\n",
    "\n",
    "polygon = Polygon(locations=shape_coords, color=\"blue\", fill_color=\"blue\", name='polygon')\n",
    "m.add_layer(polygon)\n",
    "\n",
    "for i in range(nfiles):\n",
    "    filedata = df_track.iloc[i]\n",
    "    ancillary, dfs = read_atl06(filedata.filename, verbose=False)\n",
    "    if gtx in dfs.keys():\n",
    "        df = dfs[gtx]\n",
    "        df = df[df.qual_summary == 0].copy()\n",
    "        coords = list(zip(df.lat, df.lon))\n",
    "        weight = 2 if ancillary['gtx_strength_dict'][gtx] == 'strong' else 1\n",
    "        name = '%s, track %d-%s' % (ancillary['date'], ancillary['rgt'], gtx)\n",
    "        line = Polyline(locations=coords,color=\"red\",weight=weight,fill=False, name=name, opacity=0.1)\n",
    "        m.add_layer(line)\n",
    "\n",
    "m.add_control(LayersControl())\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98bb79-06a7-40df-9fdd-e42076f6ffbd",
   "metadata": {},
   "source": [
    "### plot elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d288bc-1bae-4498-94b8-bc3dee317352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repeat = df_track.copy()\n",
    "nfiles = len(df_repeat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[9, 5], dpi=100)\n",
    "handles = []\n",
    "dfsgtx = []\n",
    "\n",
    "colors = cm.cubehelix_r(np.linspace(0.05,0.9,nfiles))\n",
    "for i in range(nfiles):\n",
    "    filedata = df_repeat.iloc[i]\n",
    "    ancillary, dfs = read_atl06(filedata.filename, verbose=False)\n",
    "    if gtx in dfs.keys():\n",
    "        df = dfs[gtx]\n",
    "        df.loc[df.qual_summary != 0,'h'] = np.nan\n",
    "        df['h_geoid_corrected'] = df.h - df.geoid_h\n",
    "        df.loc[np.abs(df.h_geoid_corrected) > 1e4,'h_geoid_corrected'] = np.nan\n",
    "        line, = ax.plot(df.xatc, df.h_geoid_corrected,lw=1, color=tuple(colors[i,:]), label=ancillary['date'])\n",
    "        # scatt = ax.scatter(0, 0 , s=10, alpha=1, color=tuple(colors[i,:]), label=ancillary['date'])\n",
    "        df['date'] = ancillary['date']\n",
    "        handles.append(line)\n",
    "        dfsgtx.append(df)\n",
    "plt.legend(handles=handles, bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, fontsize=10, ncols=1)\n",
    "dfs_all = pd.concat(dfsgtx)\n",
    "# ax.set_xlim((np.nanmin(dfs_all.lat), np.nanmax(dfs_all.lat)))\n",
    "# ax.set_ylim((np.nanmin(dfs_all.h_geoid_corrected), np.nanmax(dfs_all.h_geoid_corrected)))\n",
    "ax.set_xlabel('latitude')\n",
    "ax.set_ylabel('elevation above geoid')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7eb2d6-fbdb-4b53-bf6b-a73a2a1f175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Gillock / Kreitzer'\n",
    "dfs_all.xatc -= dfs_all.xatc.min()\n",
    "x_interp = np.arange(0, dfs_all.xatc.max(), 10)\n",
    "dates = np.unique(dfs_all.date)\n",
    "ndates = len(dates)\n",
    "colors = cm.cubehelix_r(np.linspace(0.05,0.9,ndates))\n",
    "\n",
    "# get the median across-track dist\n",
    "yatcvals_interp = []\n",
    "dhdy_interp = []\n",
    "h_vals_interp = []\n",
    "lat_interp = []\n",
    "lon_interp = []\n",
    "for i, date in enumerate(dates):\n",
    "    thisdf = dfs_all[dfs_all.date == date]\n",
    "    thisdf.loc[np.abs(thisdf.yatc)>10000, 'yatc'] = np.nan\n",
    "    thisdf.loc[np.abs(thisdf.dh_fit_dy)>1, 'dh_fit_dy'] = np.nan\n",
    "    yatcvals_interp.append(np.interp(x_interp, thisdf.xatc, thisdf.yatc))\n",
    "    dhdy_interp.append(np.interp(x_interp, thisdf.xatc, thisdf.dh_fit_dy))\n",
    "    h_vals_interp.append(np.interp(x_interp, thisdf.xatc, thisdf.h_geoid_corrected))\n",
    "    lat_interp.append(np.interp(x_interp, thisdf.xatc, thisdf.lat))\n",
    "    lon_interp.append(np.interp(x_interp, thisdf.xatc, thisdf.lon))\n",
    "\n",
    "yatcvals_interp = np.array(yatcvals_interp)\n",
    "dhdy_interp = np.array(dhdy_interp)\n",
    "h_vals_interp = np.array(h_vals_interp)\n",
    "lat_interp = np.array(lat_interp)\n",
    "lon_interp = np.array(lon_interp)\n",
    "\n",
    "yatcmid = np.array(yatcvals_interp)\n",
    "yatc25 = np.nanpercentile(yatcmid,25, axis=0)\n",
    "yatc75 = np.nanpercentile(yatcmid,75, axis=0)\n",
    "yatcmid[(yatcmid <= yatc25) |  (yatcmid >= yatc75)] = np.nan\n",
    "mean_yatc = np.array(pd.Series(np.nanmean(yatcmid,axis=0)).rolling(center=True,min_periods=1,window=1000).mean())#.reshape(1,-1)\n",
    "offtracky = yatcvals_interp - mean_yatc\n",
    "h_vals_slopecorr = h_vals_interp - offtracky * dhdy_interp\n",
    "to_discard = np.abs(offtracky) > 20\n",
    "h_vals_slopecorr[to_discard] = np.nan\n",
    "lat_interp[to_discard] = np.nan\n",
    "lon_interp[to_discard] = np.nan\n",
    "\n",
    "hmid = h_vals_slopecorr.copy()\n",
    "# h25 = np.nanpercentile(hmid, 25, axis=0)\n",
    "# h75 = np.nanpercentile(hmid, 75, axis=0)\n",
    "# hmid[(hmid <= h25) |  (hmid >= h75)] = np.nan\n",
    "# np.sum(np.isnan(hmid),axis=0)\n",
    "mean_h = np.nanmean(hmid, axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=[12, 4.5], dpi=80)\n",
    "gs = fig.add_gridspec(ncols=5, nrows=1)\n",
    "axs= [] \n",
    "axs.append(fig.add_subplot(gs[0, :2]))\n",
    "axs.append(fig.add_subplot(gs[0, 2:]))\n",
    "filename_base = ('%s_track%s_%s' % (region,track,gtx)).replace(' ','').replace('/','-')\n",
    "\n",
    "ax = axs[1]\n",
    "handles = []\n",
    "for i, date in enumerate(dates):\n",
    "    hplot = pd.Series(h_vals_slopecorr[i,:] - mean_h).rolling(center=True,min_periods=1,window=100).mean()\n",
    "    if np.sum(np.isnan(hplot)) / len(hplot) < 0.1:\n",
    "        line, = ax.plot(x_interp/1000, hplot, lw=1, color=tuple(colors[i,:]), label=date)\n",
    "        handles.append(line)\n",
    "\n",
    "meanline, = ax.plot(x_interp/1000, 0*mean_h, 'r--', lw=0.5, label='mean')\n",
    "handles.append(meanline)\n",
    "\n",
    "ax.legend(handles=handles, bbox_to_anchor=(1.04, 0.5), loc=\"center left\", borderaxespad=0, fontsize=10, ncols=1)\n",
    "ax.set_ylabel('elevation above geoid')\n",
    "ax.set_title(('%s (track %s-%s)' % (region, track, gtx)).upper())\n",
    "\n",
    "_lat = lats\n",
    "_xatc = x_interp/1000\n",
    "def lat2xatc(l):\n",
    "    return _xatc[0] + (l - _lat[0]) * (_xatc[1] - _xatc[0]) /(_lat[1] - _lat[0])\n",
    "def xatc2lat(x):\n",
    "    return _lat[0] + (x - _xatc[0]) * (_lat[1] - _lat[0]) / (_xatc[1] - _xatc[0])\n",
    "secax = ax.secondary_xaxis(-0.075, functions=(xatc2lat, lat2xatc))\n",
    "secax.xaxis.set_minor_locator(matplotlib.ticker.AutoMinorLocator())\n",
    "secax.set_xlabel('along-track distance (km) / latitude', fontsize=10)\n",
    "secax.tick_params(axis='both', which='major', labelsize=9)\n",
    "secax.ticklabel_format(useOffset=False, style='plain')\n",
    "\n",
    "ax = axs[0]\n",
    "timeS2 = '2019-01-05T00:00:00Z'\n",
    "imagery_filename = 'data/imagery/%s.tif'%filename_base\n",
    "lons = np.nanmedian(lon_interp,axis=0)\n",
    "lats = np.nanmedian(lat_interp,axis=0)\n",
    "buff = np.max(x_interp)/2*1.1\n",
    "myImage = plotS2cloudfree(lon=np.mean(lons), lat=np.mean(lats), date_time=timeS2, buffer_m=buff, max_cloud_prob=5, gamma_value=0.7, \n",
    "                imagery_filename=imagery_filename, ax=ax, download_imagery=True)\n",
    "add_inset(ax, lat, lon, inset='antarctica', loc=[0.69, 0.01], width=0.3, height=0.25)\n",
    "ximg, yimg = warp.transform(src_crs='epsg:4326', dst_crs=myImage.crs, xs=lons, ys=lats)\n",
    "ax.annotate('', xy=(ximg[-1], yimg[-1]), xytext=(ximg[0], yimg[0]),\n",
    "             arrowprops=dict(width=0.7, headwidth=5, headlength=5, color='r'),zorder=1000)\n",
    "ax.plot(ximg, yimg, 'r-', lw=0.5, zorder=500)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('%s.jpg'%filename_base, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f50c5-bebb-49a2-be90-59f890c95f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e44102-c95a-48f7-aba3-5300eb3c3755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c2212-ba6c-42ce-9fc2-eed176a0005a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
